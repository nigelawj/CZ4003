{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Object-Scene Recognition - BoW vs. SPM\n",
    "This notebook is a modification of the Spatial Pyramid Matching - Scene Recognition notebook written by TrungTVo\n",
    "- Reference Project GitHub Repo Link: https://github.com/TrungTVo/spatial-pyramid-matching-scene-recognition\n",
    "- Functions such as `computeSIFT()` and `load_dataset()` are taken as-is from the reference project\n",
    "\n",
    "Required 3rd party packages:\n",
    "- numpy > conda install numpy\n",
    "- split-folders > pip install split-folders\n",
    "- opencv via menpo channel on Anaconda Cloud > conda install -c menpo opencv\n",
    "    - OpenCV from the menpo channel is required, for the SIFT functions to be available\n",
    "- pillow via pip > pip install pillow - *NOTE: do not install via conda to avoid issues with imports*\n",
    "\n",
    "This notebook will explore Bag of Words/Features (BoW/BoF) vs. Spatial Pyramid Matching (SPM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages here\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import split_folders\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Datasets\n",
    "\n",
    "We first read in the dataset to be used: Caltech101 Dataset.\n",
    "\n",
    "The dataset can be found here: http://www.vision.caltech.edu/Image_Datasets/Caltech101/\n",
    "- Extract and place the dataset into a folder into the same location as this ipynb: e.g. *101_ObjectCategories*\n",
    "\n",
    "After which, we read in the files, and take a peep at the categories of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'accordion', 1: 'airplanes', 2: 'anchor', 3: 'ant', 4: 'BACKGROUND_Google', 5: 'barrel', 6: 'bass', 7: 'beaver', 8: 'binocular', 9: 'bonsai', 10: 'brain', 11: 'brontosaurus', 12: 'buddha', 13: 'butterfly', 14: 'camera', 15: 'cannon', 16: 'car_side', 17: 'ceiling_fan', 18: 'cellphone', 19: 'chair', 20: 'chandelier', 21: 'cougar_body', 22: 'cougar_face', 23: 'crab', 24: 'crayfish', 25: 'crocodile', 26: 'crocodile_head', 27: 'cup', 28: 'dalmatian', 29: 'dollar_bill', 30: 'dolphin', 31: 'dragonfly', 32: 'electric_guitar', 33: 'elephant', 34: 'emu', 35: 'euphonium', 36: 'ewer', 37: 'Faces', 38: 'Faces_easy', 39: 'ferry', 40: 'flamingo', 41: 'flamingo_head', 42: 'garfield', 43: 'gerenuk', 44: 'gramophone', 45: 'grand_piano', 46: 'hawksbill', 47: 'headphone', 48: 'hedgehog', 49: 'helicopter', 50: 'ibis', 51: 'inline_skate', 52: 'joshua_tree', 53: 'kangaroo', 54: 'ketch', 55: 'lamp', 56: 'laptop', 57: 'Leopards', 58: 'llama', 59: 'lobster', 60: 'lotus', 61: 'mandolin', 62: 'mayfly', 63: 'menorah', 64: 'metronome', 65: 'minaret', 66: 'Motorbikes', 67: 'nautilus', 68: 'octopus', 69: 'okapi', 70: 'pagoda', 71: 'panda', 72: 'pigeon', 73: 'pizza', 74: 'platypus', 75: 'pyramid', 76: 'revolver', 77: 'rhino', 78: 'rooster', 79: 'saxophone', 80: 'schooner', 81: 'scissors', 82: 'scorpion', 83: 'sea_horse', 84: 'snoopy', 85: 'soccer_ball', 86: 'stapler', 87: 'starfish', 88: 'stegosaurus', 89: 'stop_sign', 90: 'strawberry', 91: 'sunflower', 92: 'tick', 93: 'trilobite', 94: 'umbrella', 95: 'watch', 96: 'water_lilly', 97: 'wheelchair', 98: 'wild_cat', 99: 'windsor_chair', 100: 'wrench', 101: 'yin_yang'}\n"
     ]
    }
   ],
   "source": [
    "# Read in the dataset folder and check out category names\n",
    "# Change path name to dataset folder name - '<folder-name>/*'\n",
    "class_names = [name[21:] for name in glob.glob('101_ObjectCategories/*')]\n",
    "class_names = dict(zip(range(0,len(class_names)), class_names))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the 'split-folders' module, we then split the images into a training and test set. For this example, we will have 0.7 of the images for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test data set (Only need to run this once, unless you want to change the ratio of train_test_split; delete folder and re-run)\n",
    "split_folders.ratio('101_ObjectCategories/', output=\"101_split/\", seed=1337, ratio=(.7, .3)) # default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images into datasets\n",
    "def load_dataset(path, num_per_class=-1):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for id, class_name in class_names.items():\n",
    "        img_path_class = glob.glob(path + class_name + '/*.jpg')\n",
    "        if num_per_class > 0:\n",
    "            img_path_class = img_path_class[:num_per_class]\n",
    "        labels.extend([id]*len(img_path_class))\n",
    "        for filename in img_path_class:\n",
    "            data.append(cv2.imread(filename, 0))\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To emulate the setting as required in the Lab 2 manual, we perform training on 30 images and test on 50 images, per category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training dataset\n",
    "train_data, train_label = load_dataset('101_split/train/', 30)\n",
    "train_num = len(train_label)\n",
    "\n",
    "# load testing dataset\n",
    "test_data, test_label = load_dataset('101_split/val/', 50)\n",
    "test_num = len(test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing SIFT features\n",
    "\n",
    "Functions are defined to compute SIFT features of the images.\n",
    "\n",
    "We want to represent our training and testing images as Bag of Features histograms. We first establish a vocabulary of visual words. Then we sample local features and then perform k-means clustering on the SIFT descriptors.\n",
    "- This partitions the continuous 128 dimensional SIFT feature space into k regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute dense SIFT \n",
    "def computeSIFT(data):\n",
    "    x = []\n",
    "    for i in range(0, len(data)):\n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "        img = data[i]\n",
    "        step_size = 15\n",
    "        kp = [cv2.KeyPoint(x, y, step_size) for x in range(0, img.shape[0], step_size) for y in range(0, img.shape[1], step_size)]\n",
    "        dense_feat = sift.compute(img, kp)\n",
    "        x.append(dense_feat[1])     \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the SIFT object created to densely sample keypoints in a grid with a step-size (sampling density), and scale.\n",
    "- `sift.compute()` computes SIFT descriptors\n",
    "\n",
    "We then feed the training and test data to obtain our training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract dense sift features from training images\n",
    "x_train = computeSIFT(train_data)\n",
    "x_test = computeSIFT(test_data)\n",
    "\n",
    "all_train_desc = []\n",
    "for i in range(len(x_train)):\n",
    "    for j in range(x_train[i].shape[0]):\n",
    "        all_train_desc.append(x_train[i][j,:])\n",
    "\n",
    "all_train_desc = np.array(all_train_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then build the Bag of Words features via KMeans on the SIFT descriptors, and form Histograms to train our model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build BoW presentation from SIFT of training images \n",
    "def clusterFeatures(all_train_desc, k):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(all_train_desc)\n",
    "    return kmeans\n",
    "\n",
    "\n",
    "# form training set histograms for each training image using BoW representations\n",
    "def formHistogram(x_train, kmeans, k):\n",
    "    train_hist = []\n",
    "    for i in range(len(x_train)):\n",
    "        data = copy.deepcopy(x_train[i])\n",
    "        predict = kmeans.predict(data)\n",
    "        train_hist.append(np.bincount(predict, minlength=k).reshape(1,-1).ravel())\n",
    "        \n",
    "    return np.array(train_hist)\n",
    "    \n",
    "\n",
    "def accuracy(predict_label, test_label):\n",
    "    return np.mean(np.array(predict_label.tolist()[0]) == np.array(test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we set k = 30, and form our training and test histogram sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes ~40 mins...\n",
    "k = 30\n",
    "kmeans = clusterFeatures(all_train_desc, k)\n",
    "\n",
    "# form training and testing histograms\n",
    "train_hist = formHistogram(x_train, kmeans, k)\n",
    "test_hist = formHistogram(x_test, kmeans, k)\n",
    "\n",
    "# normalize histograms\n",
    "scaler = preprocessing.StandardScaler().fit(train_hist)\n",
    "train_hist = scaler.transform(train_hist)\n",
    "test_hist = scaler.transform(test_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Support Vector Machines (SVMs) to train our model; In particular, we use a one-vs-all LinearSVC classifier to binarise the classification problem.\n",
    "\n",
    "We test on a range of values for the parameter c, which is the penalty parameter of the error term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01 ,\t Accuracy: 25.811001410437235 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.1 ,\t Accuracy: 30.982604607428303 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.2 ,\t Accuracy: 31.170662905500706 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.3 ,\t Accuracy: 31.358721203573108 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.4 ,\t Accuracy: 31.40573577809121 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.5 ,\t Accuracy: 31.781852374236014 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.6 ,\t Accuracy: 31.781852374236014 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.7 ,\t Accuracy: 31.781852374236014 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.8 ,\t Accuracy: 31.54677950164551 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.9 ,\t Accuracy: 31.499764927127412 %\n",
      "C = 1.0 ,\t Accuracy: 31.499764927127412 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "    clf = LinearSVC(random_state=0, C=c)\n",
    "    clf.fit(train_hist, train_label)\n",
    "    predict = clf.predict(test_hist)\n",
    "    print(\"C =\", c, \",\\t Accuracy:\", np.mean(predict == test_label)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of the model improves as C increases, however the overall accuracy is low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try again with training and test set sizes of (100, 100), and k = 60\n",
    "\n",
    "We explore a little further with tweaking training and test data sizes, as well as trying a different value of k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training and test datasets, this time with (100, 100)\n",
    "train_data, train_label = load_dataset('101_split/train/', 100)\n",
    "train_num = len(train_label)\n",
    "\n",
    "test_data, test_label = load_dataset('101_split/val/', 100)\n",
    "test_num = len(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract dense sift features from training images\n",
    "x_train = computeSIFT(train_data)\n",
    "x_test = computeSIFT(test_data)\n",
    "\n",
    "all_train_desc = []\n",
    "for i in range(len(x_train)):\n",
    "    for j in range(x_train[i].shape[0]):\n",
    "        all_train_desc.append(x_train[i][j,:])\n",
    "\n",
    "all_train_desc = np.array(all_train_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes > 1 hr...\n",
    "k = 60\n",
    "kmeans = clusterFeatures(all_train_desc, k)\n",
    "\n",
    "# form training and testing histograms\n",
    "train_hist = formHistogram(x_train, kmeans, k)\n",
    "test_hist = formHistogram(x_test, kmeans, k)\n",
    "\n",
    "# normalize histograms\n",
    "scaler = preprocessing.StandardScaler().fit(train_hist)\n",
    "train_hist = scaler.transform(train_hist)\n",
    "test_hist = scaler.transform(test_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01 ,\t Accuracy: 39.76753839767538 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.1 ,\t Accuracy: 44.831880448318806 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.2 ,\t Accuracy: 44.707347447073474 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.3 ,\t Accuracy: 44.79036944790369 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.4 ,\t Accuracy: 44.87339144873391 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.5 ,\t Accuracy: 44.74885844748858 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.6 ,\t Accuracy: 44.624325446243255 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.7 ,\t Accuracy: 44.58281444582815 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.8 ,\t Accuracy: 44.3752594437526 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.9 ,\t Accuracy: 44.12619344126193 %\n",
      "C = 1.0 ,\t Accuracy: 44.167704441677046 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "    clf = LinearSVC(random_state=0, C=c)\n",
    "    clf.fit(train_hist, train_label)\n",
    "    predict = clf.predict(test_hist)\n",
    "    print (\"C =\", c, \",\\t Accuracy:\", np.mean(predict == test_label)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall accuracy has improved. Accuracy improves as C changes as before, but the model has performed better with k=60, and larger training and test images sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try SPM\n",
    "\n",
    "Now, we attempt to improve performance with Spatial Pyramid Matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def extract_denseSIFT(img):\n",
    "    DSIFT_STEP_SIZE = 2\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    disft_step_size = DSIFT_STEP_SIZE\n",
    "    keypoints = [cv2.KeyPoint(x, y, disft_step_size)\n",
    "            for y in range(0, img.shape[0], disft_step_size)\n",
    "                for x in range(0, img.shape[1], disft_step_size)]\n",
    "\n",
    "    descriptors = sift.compute(img, keypoints)[1]\n",
    "    \n",
    "    return descriptors\n",
    "\n",
    "\n",
    "# form histogram with Spatial Pyramid Matching upto level L with codebook kmeans and k codewords\n",
    "def getImageFeaturesSPM(L, img, kmeans, k):\n",
    "    W = img.shape[1]\n",
    "    H = img.shape[0]   \n",
    "    h = []\n",
    "    for l in range(L+1):\n",
    "        w_step = math.floor(W/(2**l))\n",
    "        h_step = math.floor(H/(2**l))\n",
    "        x, y = 0, 0\n",
    "        for i in range(1,2**l + 1):\n",
    "            x = 0\n",
    "            for j in range(1, 2**l + 1):                \n",
    "                desc = extract_denseSIFT(img[y:y+h_step, x:x+w_step])                \n",
    "\n",
    "                predict = kmeans.predict(desc)\n",
    "                histo = np.bincount(predict, minlength=k).reshape(1,-1).ravel()\n",
    "                weight = 2**(l-L)\n",
    "                h.append(weight*histo)\n",
    "                x = x + w_step\n",
    "            y = y + h_step\n",
    "            \n",
    "    hist = np.array(h).ravel()\n",
    "    \n",
    "    # normalize hist\n",
    "    dev = np.std(hist)\n",
    "    hist -= np.mean(hist)\n",
    "    hist /= dev\n",
    "    return hist\n",
    "\n",
    "\n",
    "# get histogram representation for training/testing data\n",
    "def getHistogramSPM(L, data, kmeans, k):    \n",
    "    x = []\n",
    "    for i in range(len(data)):        \n",
    "        hist = getImageFeaturesSPM(L, data[i], kmeans, k)        \n",
    "        x.append(hist)\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_histo = getHistogramSPM(2, train_data, kmeans, k)\n",
    "test_histo = getHistogramSPM(2, test_data, kmeans, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01 ,\t\t Accuracy: 58.779576587795766 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.1 ,\t\t Accuracy: 56.08136156081361 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.2 ,\t\t Accuracy: 55.50020755500208 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.3 ,\t\t Accuracy: 55.25114155251142 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.4 ,\t\t Accuracy: 55.2096305520963 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.5 ,\t\t Accuracy: 55.168119551681194 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.6 ,\t\t Accuracy: 55.2096305520963 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.7 ,\t\t Accuracy: 55.168119551681194 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.8 ,\t\t Accuracy: 55.33416355334163 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.9 ,\t\t Accuracy: 55.12660855126609 %\n",
      "C = 1.0 ,\t\t Accuracy: 55.002075550020756 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legin\\Miniconda3\\envs\\cz4003\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# train SVM\n",
    "for c in [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "    clf = LinearSVC(random_state=0, C=c)\n",
    "    clf.fit(train_histo, train_label)\n",
    "    predict = clf.predict(test_histo)\n",
    "    print(\"C =\", c, \",\\t\\t Accuracy:\", np.mean(predict == test_label)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that C could be set as 0.01, offering an accuracy of approximately 58.78%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "We have implemented the Bag of Words/Features (BoW/BoF) model to represent the features of images in visual words. These features are extracted from SIFT descriptors built. Each SIFT descriptor is a Nx128 dimensional matrix, with N = no. of key points in each image.\n",
    "\n",
    "KMeans clustering is performed to cluster features into groups known as codewords. These codewords make up a dictionary (codebook) of K different codewords, each represented by the cluster centroids.\n",
    "- K random cluster centroids are initialised and SIFT features are assigned to a cluster based on nearest distances based on a distance metric\n",
    "- Centroids are recomputed until convergence occurs; Centroids represent the mean of all points in the cluster\n",
    "\n",
    "With the Bag of Features, they can then be represented as a set of histograms. Then we classify them using SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements via Spatial Pyramid Matching (SPM)\n",
    "\n",
    "The BoW model encodes all local features into a single code vector, and information on the position of feature descriptors are dropped. Hence, spatial information between words are not preserved.\n",
    "\n",
    "Spatial Pyramid Matching breaks the image up into different regions and subregions to compute SIFT descriptors in each subregion, then form the histogram of visual words and concatenate them into a single 1D vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements of model performance\n",
    "\n",
    "Via hyperparameter tuning, we can find the optimal value of the hyperparameters such as C, in the case of SVM, and increase accuracy of the model.\n",
    "\n",
    "Other models can be applied as well, and performances of various classification techniques such as KNearestNeighbors can be compared, or be ensembled."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
